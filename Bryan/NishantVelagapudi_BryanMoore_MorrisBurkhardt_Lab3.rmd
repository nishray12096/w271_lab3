---
title: 'Statistical Methods for Discrete Response, Time Series, and Panel Data (W271):
  Lab 3'
author: "Professor Jeffrey Yau"
date: "March 18, 2018"
geometry: margin = 1 cm
output:
  pdf_document: default
---
\fontsize{9}{10}
\selectfont

******************************************************

## Introduction

<INSERT NARRATIVE>

### Load packages set some formatting preferences
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Set digit print output to max desired
options(digits=2)
# Clean up the workspace before we begin
rm(list = ls())
# Load libraries
library(car)
library(dplyr)
library(Hmisc)
library(forecast)
library(astsa)
library(xts)
library(vars)
```

```{r Pkg and Data Load, message = FALSE, warning=FALSE}
pkg <- c('knitr', 'Hmisc', 'ggcorrplot', 'car',
         'dplyr', 'ggplot2', 'jtools', 'readr')
invisible(lapply(pkg, require, character.only = T))
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

### Question 1: E-Commerce Retail Sales as a Percent of Total Sales- Build a Seasonal ARIMA model and generate quarterly forecast for 2017

### Load data and quality-check the raw data
```{r}
# Load csv file as df
df_q1 <- read.csv("ECOMPCTNSA.csv", header = TRUE, sep=",")
str(df_q1)
#View(df_q1)
#names(df_q1)
head(df_q1)
describe(df_q1)
# Create an R time-series object with our quarterly data starting with final quarter of 1999
q1_ts <- ts(df_q1$ECOMPCTNSA, frequency = 4, start = c(1999,4))
str(q1_ts)
head(q1_ts)
```

We see that there are no missing values and that we are working with quarterly time series data.  No anomalies are detected and there is not potential for top or bottom code. On gross visual inspection of the time series, we see that the starting values are all less than 1, with the later values all being greater than 7.  This leads us to already suspect we are not dealing with a stationary series.  We cannot make a confident comment on seasonality without further EDA for visualization.

### EDA

#### Plot the data
```{r, out.width='.49\\linewidth', fig.width=7, fig.height=4, fig.show='hold', fig.align='center', strip.white=TRUE}
# For modeling purposes we keep data between 1999 and 2015 as our training data; we hold-out 2015-2016 as test data
q1_ts_train <- q1_ts[time(q1_ts) >= 1999 & time(q1_ts) < 2015]
q1_ts_train <- ts(q1_ts_train, frequency = 4, start = c(1999,4))
q1_ts_test <- q1_ts[time(q1_ts) >= 2015]
q1_ts_test <- ts(q1_ts_test, frequency = 4, start = c(2015,1))
# Plot the training data
plot.ts(q1_ts_train, main="Quarterly data of E-Commerce Retail Sales as a Percent of Total Sales", ylab="Percent of total sales", col='blue')
```

We are now able to clearly see that the e-commernce retail sales time series is not stationary in the mean and exhibits seasonality. We will attempt to stationarize our time series via differencing.

#### Examine the ACF/PACF to determine if an AR(p) or MA(q) model is appropriate
```{r, out.width='.49\\linewidth', fig.width=7, fig.height=3.5, fig.show='hold', fig.align='center', strip.white=TRUE}
# Plot frequency distribution, ACF, PACF
hist(q1_ts_train, main="Frequency Distribution of E-commerce as Percentage of Total Sales", xlab="E-commerce as percentage of total sales")
acf(q1_ts_train, main="Autocorrelation function", lag.max = 24)
pacf(q1_ts_train, main="Partial Autocorrelation function", lag.max = 24)
```

Although it has been dictated that we are to create a SARIMA model, we still need to check that this model is appropriate.We see that the autocorrelations are significant for a large number of lag (16 quarters). This slow decay in the autocorrelations is evidence of a trend in the data, thus telling us that the time series is not stationary. The gradual decay without any spikes at seasonal intervals tells us that we will need a non-seasonal AR term p but will not need a seasonal AR term P.
We see that the partial autocorrelation plot has a significant spike at a lag of 1 quarter and at 4 quarters.  We see that our PACF has a somewhat abrupt drop-off non-seasonally following lag-1 and but that there are spikes in the PACF at an annual lag (multiples of lag-4 given our quarterly data).  This leads us to believe that our model will not require a non-seasonal MA term q but will require a seasonal MA term Q.  The histogram of our data shows that the e-commerce as percentage of total sales is fairly normally distributed with positive skew; however, this tells us nothing about how the data are related in time.

#### Difference the data to impose stationarity
We have demonstrated evidence of both trend and seasonality in our time series.  To impose stationarity, we will first apply a seasonal difference to the data and then re-evaluate the trend.  If a trend remains, then  we will take first differences.
```{r, out.width='.49\\linewidth', fig.width=7, fig.height=3.5, fig.show='hold', fig.align='center', strip.white=TRUE}
# Impose seasonal difference at one-year (4 quarters)
q1_ts_train_seasonal_diff = diff(q1_ts_train,4)
plot.ts(q1_ts_train_seasonal_diff, main="Quarterly E-Commerce Sales as % Total Sales- Seasonal Difference", ylab="Percent of total sales", col='green')
acf(q1_ts_train_seasonal_diff, main="Autocorrelation function", lag.max = 24)
pacf(q1_ts_train_seasonal_diff, main="Partial Autocorrelation function", lag.max = 24)
```

After creating a seasonal-differenced series, the series still appears to be non-stationary. For stationary time series, the ACF drops to zero relatively quickly, while for non-stationary data the ACF decreases slowly.  We see improvement here as compared to out initial non-differenced model, but we have still not imposed stationarity.  This provides evidence that we need to impose a first-difference. 

```{r, out.width='.49\\linewidth', fig.width=7, fig.height=3.5, fig.show='hold', fig.align='center', strip.white=TRUE}
# Impose additional first-difference
q1_ts_train_seasonal_and_first_diff = diff(q1_ts_train_seasonal_diff,1)
plot.ts(q1_ts_train_seasonal_and_first_diff, main="Quarterly E-Commerce Sales as % Total Sales- Seasonal & First Difference", ylab="Percent of total sales", col='red')
acf(q1_ts_train_seasonal_and_first_diff, main="Autocorrelation function", lag.max = 24)
pacf(q1_ts_train_seasonal_and_first_diff, main="Partial Autocorrelation function", lag.max = 24)
```
After taking a first-difference we see that the seasonal-differenced and first-differenced series is stationary.  Overall we do not see evidence that the volatility is increasing over time, so we do not take a difference in log to stabilize the series.

### Order Identification
The spike in the ACF at a lag of 1 quarter suggests a nonseasonal MA(1) (q=1) component and the spikes at intervals of 4 quarters of lag out to approximately lag 16 suggest a seasonal MA(4) (Q=4).  Additionally, the spike at at a lag of 1 quarter in the PACF and the spikes at intervals of 4 quarters of lag tells us that a a nonseasonal AR(1) (p=1) component and a seasonal AR(1) (P=1) component are appropriate for our initial model.  Therefore, our initial model will be of the form $ARIMA(1,1,1)(1,1,4)_4$

### Model Creation: Build a Seasonal ARIMA model and generate quarterly forecast for 2017
We first start by building a model with our estimated components from our prior analysis.  Next, we will see if an interative method comparing difference combinations of component values as well as the auto.arima function all agree with our model having the lowest AIC/BIC.
```{r, out.width='.49\\linewidth', fig.width=7, fig.height=3.5, fig.show='hold', fig.align='center', strip.white=TRUE}
q1_ts_train.fit <- Arima(q1_ts_train, order=c(1,1,1), seasonal=c(1,1,4))
summary(q1_ts_train.fit)
plot.ts(q1_ts_train.fit$resid, main="Baseline Model Residuals vs Time", ylab="Residual", col='black')
hist(q1_ts_train.fit$resid, main="Frequency Distribution of Baseline Model Residuals", xlab="Residual")
acf(q1_ts_train.fit$resid, main="Autocorrelation function", lag.max = 24)
shapiro.test(q1_ts_train.fit$resid)
qqnorm(q1_ts_train.fit$resid)
qqline(q1_ts_train.fit$resid)
Box.test(q1_ts_train.fit$resid, type = "Ljung-Box")
```
We see that our baseline $ARIMA(1,1,1)(1,1,4)_4$ model generates an AIC of -78. We conduct a Shapiro-Wilk normality test for our residuals, which shows that we fail to reject the null hypothesis that the population from which our residuals are derived is normal.  We also conduct a Box-Ljung test. The p-value is large, which means we do not suspect that there is non-zero autocorrelation within the lags.
Looking at the plot of the residuals, we see that the variance is increased somewhat at the center of the plot but that overall the variance is not increasing over time. The histogram of our residuals shows a somewhat normal distribution with a positive skew.  Looking at the ACF plot, we do not see evidence of autocorrelation in the residuals, which suggests that there is not information that has not been accounted for in the model. Our Q-Q plot supports that our residuals are normally distributed.

Now we will look at other values for p,d,q,P,D,Q via an iterative method. We will impose both first-order non-seasonal and first-order seasonal minimum differencing on our iterative search here, per our prior EDA.
```{r, out.width='.49\\linewidth', fig.width=7, fig.height=3.5, fig.show='hold', fig.align='center', strip.white=TRUE}
mod_AIC <- 0
for(P in 0:2){
  for(Q in 0:2){
    for(D in 1:4){
      for(p in 0:2){
        for(q in 0:2){
          for(d in 1:2){
            mod <- Arima(q1_ts_train, order = c(p,d,q),
                    seasonal = list(order = c(P,D,Q),4),
                    method = "ML")
            if (mod$aic<mod_AIC){
            mod_AIC <- mod$aic
            best_params <- c(p,d,q,P,D,Q)
      }
          }
        }
      }
    }
  }
}
print(c(best_params, mod_AIC))
```
Interestingly, our iterative method to determine the values of p,d,q,P,D,Q in our SARIMA model that are associated with the lowest AIC value tells us that the model with the lowest AIC is $ARIMA(0,1,1)(1,1,2)_4$. The AIC for this model is lower than for our baseline model (-93 vs -78). We now look at the residuals for this model.

```{r, out.width='.49\\linewidth', fig.width=7, fig.height=3.5, fig.show='hold', fig.align='center', strip.white=TRUE}
# Residual diagnostics on iterative model
q1_ts_train_it.fit <- Arima(q1_ts_train, order=c(0,1,1), seasonal=c(1,1,2))
summary(q1_ts_train_it.fit)
plot.ts(q1_ts_train_it.fit$resid, main="Iterative Model Residuals vs Time", ylab="Residual", col='black')
hist(q1_ts_train_it.fit$resid, main="Frequency Distribution of Iterative Model Residuals", xlab="Residual")
acf(q1_ts_train_it.fit$resid, main="Autocorrelation function", lag.max = 24)
shapiro.test(q1_ts_train_it.fit$resid)
qqnorm(q1_ts_train_it.fit$resid)
qqline(q1_ts_train_it.fit$resid)
Box.test(q1_ts_train_it.fit$resid, type = "Ljung-Box")
```
Similar to our baseline model, the Shapiro-Wilk normality test shows evidence that our residuals are derived from a normal population.  The Box-Ljung test shows that there is evidence of zero autocorrelation within the lags.
Overall the variance is not increasing over time. The histogram of our residuals shows a fairly normal distribution. Looking at the ACF plot, we do not see evidence of autocorrelation in the residuals. Our Q-Q plot supports that our residuals are normally distributed.

We will proceed with the auto-arima() function to also provide evidence for the order of the model.
```{r, out.width='.49\\linewidth', fig.width=7, fig.height=3.5, fig.show='hold', fig.align='center', strip.white=TRUE}
auto.arima(q1_ts_train, seasonal=TRUE)
```
We see that the auto.arima function has determined that the model, as evaluated with stepwise argument on, that yields the lowest AIC is different from both out proposed baseline model and from our model generated by the iterative procedure.  The auto.arima best model per AIC is $ARIMA(0,1,1)(0,1,0)_4$ We now look at the residuals for the auto.arima generated model.

```{r, out.width='.49\\linewidth', fig.width=5, fig.height=4, fig.show='hold', fig.align='center', strip.white=TRUE}
# Residual diagnostics on auto.arima model
q1_ts_train_auto.fit <- Arima(q1_ts_train, order=c(0,1,1), seasonal=c(0,1,0))
summary(q1_ts_train_auto.fit )
plot.ts(q1_ts_train_auto.fit $resid, main="auto.arima Model Residuals vs Time", ylab="Residual", col='black')
hist(q1_ts_train_auto.fit $resid, main="Frequency Distribution of auto.arima Model Residuals", xlab="Residual")
acf(q1_ts_train_auto.fit $resid, main="Autocorrelation function", lag.max = 24)
shapiro.test(q1_ts_train_auto.fit $resid)
qqnorm(q1_ts_train_auto.fit $resid)
qqline(q1_ts_train_auto.fit $resid)
Box.test(q1_ts_train_auto.fit $resid, type = "Ljung-Box")
```
Similar to our baseline model and to our model generated by our iterative method, the Shapiro-Wilk normality test shows evidence that our residuals are derived from a normal population.  The Box-Ljung test shows that there is evidence of zero autocorrelation within the lags.
Overall the variance is not increasing over time. The histogram of our residuals shows a fairly normal distribution with a positive skew. Looking at the ACF plot, we do not see evidence of autocorrelation in the residuals. Our Q-Q plot supports that our residuals are normally distributed.

### Fit Evaluation
We already looked at the in-sample performance of our candidate models by looking at their residuals.  Our "iterative" SARIMA model $ARIMA(0,1,1)(1,1,2)_4$ had the lowest AIC at -93.  Our baseline model $ARIMA(1,1,1)(1,1,4)_4$ had an intermediate AIC at -87. Our auto-arim model $ARIMA(0,1,1)(0,1,0)_4$ had the highest AIC at -81.
Now, we look at the out-of-sample performance of our candidate models by forecasting the quarterly retail sales in 2015 and 2016.  We will determine which model has the lowest forecasting error.
```{r, out.width='.49\\linewidth', fig.width=5, fig.height=4, fig.show='hold', fig.align='center', strip.white=TRUE}
# Out-of-sample performance: Forecasting the quarterly E-Commerce retail sales in 2015 and 2016 with our models
# There are 8 observations in the test set (2015-2016), thus we generate an 8-step ahead forecast from the training set.
library(forecast)
library(tseries)
forecast_base <- forecast(q1_ts_train.fit, h = 8)
plot(forecast_base)
forecast_it <- forecast(q1_ts_train_it.fit, h = 8)
plot(forecast_it)
forecast_auto <- forecast(q1_ts_train_auto.fit, h = 8)
plot(forecast_auto)
#Calculate RMSE
compare.forecast.df <- data.frame(forecast_base = forecast_base$mean,
                                  forecast_it = forecast_it$mean,
                                  forecast_auto = forecast_auto$mean,
                                  testdata = q1_ts_test)
# Calculate RMSE
calculate_rmse <- function(fcast, test){
  rmse <- sqrt(mean((fcast - test)^2))
}
print(calculate_rmse(compare.forecast.df$forecast_base, compare.forecast.df$testdata))
print(calculate_rmse(compare.forecast.df$forecast_it, compare.forecast.df$testdata))
print(calculate_rmse(compare.forecast.df$forecast_auto, compare.forecast.df$testdata))
```
We see that model dictated by the auto-arim method $ARIMA(0,1,1)(0,1,0)_4$ actually has the lowest RMSE despite having the highest AIC of the three candidate models.  Lower values of RMSE indicate better fit, seen here as the lowest forecasting error for the out-of-sample data from 2015-2016.  Thus, we choose $ARIMA(0,1,1)(0,1,0)_4$ as our model to forecast for 2017.

```{r, out.width='.49\\linewidth', fig.width=5, fig.height=4, fig.show='hold', fig.align='center', strip.white=TRUE}
#Forecast beyond the observed time-period of the series: generate quarterly forecast for 2017
#Given the AR and MA components in our model, we cannot hold-out 2015-2016 in predicting 2017.  Therefore we need to use the auto.arima again to generate a predictive model for 2017 using our entire initial time series through 2016.
auto.arima(q1_ts, seasonal=TRUE)
q1_ts_auto.fit <- Arima(q1_ts, order=c(0,1,1), seasonal=c(0,1,0))
q1_ts_pred_2017 <- predict(q1_ts_auto.fit, n.ahead = 4, ci = 0.95)
q1_ts_pred_2017
# Alternate [INCORRECT] method: Extend train model another 4 quarters into 2017
#q1_ts_train_pred_2017 <- predict(q1_ts_train_auto.fit, n.ahead = 12, ci = 0.95)
#q1_ts_train_pred_2017
```
<Yau actually does this by going back and creating a model from the entire initial ts, not by simply extending the forecasts from the train ts further into the future. Approach regarding new model with entire ts vs extending our train model forecast?>

We see that the quarterly forecasted percentages of E-commerce sales of total sales are 8.5, 8.3, 8.5, and 10.3.

### Question 2: data_2018Spring_MTS.txt

### Load data
```{r, out.width='.49\\linewidth', fig.width=5, fig.height=4, fig.show='hold', fig.align='center', strip.white=TRUE}
# Load txt file as df
df_q2 <- read.table("data_2018Spring_MTS_v2.txt", header = TRUE)
#View(df_q2)
head(df_q2)
describe(df_q2)
# Create R time-series objects with our monthly data starting with January 1947
q2_ts_series1 <- ts(df_q2$series1, frequency = 12, start = c(1947,1))
q2_ts_series2 <- ts(df_q2$series2, frequency = 12, start = c(1947,1))
q2_ts_series3 <- ts(df_q2$series3, frequency = 12, start = c(1947,1))
q2_ts_series4 <- ts(df_q2$series4, frequency = 12, start = c(1947,1))
```
We see that there are no missing values and that we are working with monthly time series data.  No anomalies are detected and there is not potential for top or bottom code.

### EDA
#### Generate ts objects, segment train/test sets and plot the data
```{r, out.width='.49\\linewidth', fig.width=7, fig.height=4, fig.show='hold', fig.align='center', strip.white=TRUE}
# For modeling purposes we keep data between 1947 and the end of 1992 as our training data; we hold-out 1993 as test data
q2_ts_series1_train <- q2_ts_series1[time(q2_ts_series1) >= 1947 & time(q2_ts_series1) < 1993]
q2_ts_series2_train <- q2_ts_series2[time(q2_ts_series2) >= 1947 & time(q2_ts_series2) < 1993]
q2_ts_series3_train <- q2_ts_series3[time(q2_ts_series3) >= 1947 & time(q2_ts_series3) < 1993]
q2_ts_series4_train <- q2_ts_series4[time(q2_ts_series4) >= 1947 & time(q2_ts_series4) < 1993]
q2_ts_series1_train <- ts(q2_ts_series1_train, frequency = 12, start = c(1947,1))
q2_ts_series2_train <- ts(q2_ts_series2_train, frequency = 12, start = c(1947,1))
q2_ts_series3_train <- ts(q2_ts_series3_train, frequency = 12, start = c(1947,1))
q2_ts_series4_train <- ts(q2_ts_series4_train, frequency = 12, start = c(1947,1))

# Our test data will span from the start of 1993 to the end of 1993
q2_ts_series1_test <- q2_ts_series1[time(q2_ts_series1) >= 1993]
q2_ts_series2_test <- q2_ts_series2[time(q2_ts_series2) >= 1993]
q2_ts_series3_test <- q2_ts_series3[time(q2_ts_series3) >= 1993]
q2_ts_series4_test <- q2_ts_series4[time(q2_ts_series4) >= 1993]
q2_ts_series1_test <- ts(q2_ts_series1_test, frequency = 12, start = c(1993,1))
q2_ts_series2_test <- ts(q2_ts_series2_test, frequency = 12, start = c(1993,1))
q2_ts_series3_test <- ts(q2_ts_series3_test, frequency = 12, start = c(1993,1))
q2_ts_series4_test <- ts(q2_ts_series4_test, frequency = 12, start = c(1993,1))

# Plot the training data for all four time series
ts.plot(q2_ts_series1_train, q2_ts_series2_train, q2_ts_series3_train, q2_ts_series4_train, gpars=list(main="Series", ylab="Unknown units", col=c('blue','red','green','black')))
legend("topleft",c("Series 1","Series 2","Series 3","Series 4"),lty=1,col=c('blue','red','green','black'),bty='n',cex=.75)

# Show the correlation between ther series
cor(df_q2[3:6])
```
We can clearly see that none of the four time series are stationary. There does not appear to be an obvious seasonal trend within any of the four time series. We need to atempt to stationarize our time series via differencing.  There also appears to be high correlation between the four time series.  This is confirmed with the cor() function, showing that the correlation between any given time series pair is greater than 0.94.  All four of the series appear to be a random walk.

#### Examine the ACF/PACF
```{r, out.width='.49\\linewidth', fig.width=7, fig.height=3.5, fig.show='hold', fig.align='center', strip.white=TRUE}
# Plot frequency distribution, ACF, PACF for each series
hist(q2_ts_series1_train, main="Frequency Distribution of Series 1", xlab="Series 1")
acf(q2_ts_series1_train, main="Autocorrelation function", lag.max = 24)
pacf(q2_ts_series1_train, main="Partial Autocorrelation function", lag.max = 24)
hist(q2_ts_series2_train, main="Frequency Distribution of Series 2", xlab="Series 2")
acf(q2_ts_series2_train, main="Autocorrelation function", lag.max = 24)
pacf(q2_ts_series2_train, main="Partial Autocorrelation function", lag.max = 24)
hist(q2_ts_series3_train, main="Frequency Distribution of Series 3", xlab="Series 3")
acf(q2_ts_series3_train, main="Autocorrelation function", lag.max = 24)
pacf(q2_ts_series3_train, main="Partial Autocorrelation function", lag.max = 24)
hist(q2_ts_series4_train, main="Frequency Distribution of Series 4", xlab="Series 4")
acf(q2_ts_series4_train, main="Autocorrelation function", lag.max = 24)
pacf(q2_ts_series4_train, main="Partial Autocorrelation function", lag.max = 24)
# Unit root tests to confirm non-stationarity
adf.test(q2_ts_series1_train)
adf.test(q2_ts_series2_train)
adf.test(q2_ts_series3_train)
adf.test(q2_ts_series4_train)
```
We see that the distributions for the series are fairly uniform except for Series 3, which has a an exponential distribution. All four of the series show autocorrelation that "tails-off" with significant autocorrelation at a high number of lags. Additionally, all four of the series show that the partial autocorrelation cuts-off after lag q = 1, meaning that the autocorrelations at lag 2 and beyondare due to propogation of the autocorrelation at lag 1.  This informs our model by telling us that an VAR(1) should be used and that we are unlikely to need a non-seasonal MA components in our model. We also know that the VAR model captures a large amount of model dynamics and that obtaining a VARMA model can be computationally difficult. Thus we will proceed with a VAR model.
We perform augmented Dickey-Fuller tests for stationarity on all four series, where the null hypothesis is that the series has a unit root.  If we cannot reject the null hypothesis, then it means that there is a unit root and that the series is not stationary. We see that for Series 1-3 we cannot reject the null hypothesis and must treat Series 1-3 as non-stationary. The p-value for Series 1 approaches the level of significance but does not achieve it. We can reject the null hypothesis for Series 4 and treat Series 4 as stationary.

#### Determination of Cointegration and Differencing the series to impose stationarity
Two non-stationary time series are cointegrated if some linear combination of the two time series is stationary.  Here we will test for cointegration within our previously demonstrated non-stationary Series 1-3.
```{r, out.width='.49\\linewidth', fig.width=7, fig.height=3.5, fig.show='hold', fig.align='center', strip.white=TRUE}
# Phillips-Ouliaris Cointegration Test
q2_ts_mv_1_to_3 <- ts(df_q2[3:5], frequency = 12, start = c(1947,1))
po.test(cbind(q2_ts_mv_1_to_3))
# Difference Series 1-3 individually until stationary per Dickey-Fuller test
diff_1_q2_ts_series1_train <- diff(q2_ts_series1_train,1)
diff_1_q2_ts_series2_train <- diff(q2_ts_series2_train,1)
diff_1_q2_ts_series3_train <- diff(q2_ts_series3_train,1)
# Dickey-Fuller test for stationarity of final differenced series
adf.test(diff_1_q2_ts_series1_train)
adf.test(diff_1_q2_ts_series2_train)
adf.test(diff_1_q2_ts_series3_train)
```
We see that time series 1-3 are not cointegrated per our p-value of 0.1, therefore we will not proceed with a conintegration to attempt to impose stationarity as we cannot reject the null hypothesis that states that the time series are not cointegrated.  We should not fit linear regression models of Series 1-3 on each other for modeling. Instead, we proceed with first-differencing within each individual Series 1-3 to impose stationarity.  We see per the results of our Dickey-Fuller test on each of the first-differenced Series 1-3 that the first-differenced series is now stationary for Series 1-3.

### Order Identification
```{r, out.width='.49\\linewidth', fig.width=7, fig.height=3.5, fig.show='hold', fig.align='center', strip.white=TRUE}
# Use Varselect to determine lag optimization for VAR model. Of note we must take-out the first value from Series 4 since the other series are all differenced and we need to maintain consistent number of rows between the series
q2_ts_series4_train_for_mv <- window(q2_ts_series4_train, start=c(1947,2))
series1_as_df <- data.frame(Y=as.matrix(diff_1_q2_ts_series1_train), date=time(diff_1_q2_ts_series1_train))
series2_as_df <- data.frame(Y=as.matrix(diff_1_q2_ts_series2_train), date=time(diff_1_q2_ts_series2_train))
series3_as_df <- data.frame(Y=as.matrix(diff_1_q2_ts_series3_train), date=time(diff_1_q2_ts_series3_train))
series4_as_df <- data.frame(Y=as.matrix(q2_ts_series4_train_for_mv), date=time(q2_ts_series4_train_for_mv))
mv_df <- cbind(series1_as_df,series2_as_df,series3_as_df,series4_as_df)
mv_df <- mv_df[c(1,3,5,7,8)]
VARselect(mv_df, lag.max=10, type="both")
```
Per VARselect and seeking to minimize our AIC, we should proceed with a VAR(2) model

### Model Creation
```{r, out.width='.49\\linewidth', fig.width=7, fig.height=3.5, fig.show='hold', fig.align='center', strip.white=TRUE}
mv_df <- mv_df[c(1,2,3,4)]
mv_model <- VAR(mv_df[],p=2, type="both")
summary(mv_model)
```


### Fit Evaluation
```{r}

```


## Conclusion
<Insert conclusion narrative>