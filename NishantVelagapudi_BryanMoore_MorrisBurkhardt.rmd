---
title: "Lab 3"
author: "Nishant Velagapudi, Bryan Moore, Morris Burkhardt - Overall"
date: "March 19, 2018"
geometry: margin = 1.5 cm
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

pkg <- c('knitr', 'Hmisc', 'ggcorrplot', 'car','xts','forecast',
         'dplyr', 'ggplot2', 'jtools', 'readr', 'astsa', 'vars', 'dplyr','tseries', 'GGally')
invisible(lapply(pkg, require, character.only = T))
```

# Question 1: E-Commerce Retail Sales as a Percentage of Total Sales
We have a time series that describes the percentage of sales attributed to e-commerce. Modelling this series will require three major steps. First, we will explore and visualize the series to understand potential transformations as well as AR and MA orders. Second, we will find the SARIMA specification with the optimal AIC value. Finally, we will compare various model specifications (informed either through our EDA or our AutoArima results) on the basis of model performance in a hold-out data set. Data up until 2015 will be used for training, with 2015 and 2016 data being used for model selection. We generate a forecast for 2017 data using the best-performing specification trained over all data available.

## Exploration and Visualization

Although it has been dictated that we are to create a SARIMA model, we will use exploratory analysis to show that this is suitable.

```{r}
# loading the data and making the train-test split
ecom = read.csv(file = "ECOMPCTNSA.csv")
ts_ecom = ts(ecom$ECOMPCTNSA, start = c(1999, 4), frequency = 4)
ts_ecom_train = ts(ts_ecom[time(ts_ecom) < 2015], start = c(1999, 4), freq = 4)
ts_ecom_test = ts(ts_ecom[time(ts_ecom) >= 2015], start = c(2015, 1), freq = 4)
head(ts_ecom_train, 13)

#check for missing values
sum(is.na(ts_ecom_train))

#summarize the series
summary(ts_ecom_train)
```

We can see that we have no missing values in this series: the series ranges from 0.7 to 9.5 with a mean of 3.8 and median of 3.6. 

```{r, fig.height=3.2}
#visualize the series
plot(ts_ecom_train, xlab = 'Date', ylab = 'E-Commerce Retail Sales',
     main = 'E-commerce Sales: % of Total From 1999-2016')
lines(ma(ts_ecom_train, order = 4, centre = T), col = 'green')
```

Plotting this series shows both a deterministic trend as well as strong seasonality. A MA(4) model of this series smooths out all variance: reinforcing the observation that we have annual seasonality in this series. We next look at autocorrelation and partial autocorrelation functions of the training series.

```{r,fig.height=4}
par(mfrow=c(1,2))
acf(ts_ecom_train)
pacf(ts_ecom_train)
```

We see that the autocorrelations are significant for a large number of lag (16 quarters), further evidence of non-stationarity. The gradual decay without any spikes at seasonal intervals tells us that we will likely need a non-seasonal AR term p but may not need a seasonal AR term P.

Imposing stationarity will require differencing the series. We take first and fourth order differences as well as the first order difference of the fourth order differences. 

```{r, warning=FALSE,message=FALSE}
par(mfrow=c(2,2), mai = c(.3, 0.3, 0.3, 0.1))
log_ts_ecom_train = log(ts_ecom_train)
log_ts_ecom_test = log(ts_ecom_test)

plot(diff(ts_ecom_train, lag = 4),xlab=NULL,ylab=NULL,main = "Lag 4 Differenced Series")
plot(diff(diff(ts_ecom_train, lag = 4),lag=1),xlab=NULL,ylab=NULL,
     main = "Lag 1 Difference of Lag 4 Difference")
plot(diff(log_ts_ecom_train, lag = 1),xlab=NULL,ylab=NULL,main = "Lag 1 Differenced Log Series")
plot(diff(log_ts_ecom_train, lag = 4),xlab=NULL,ylab=NULL,main = "Lag 4 Differenced Log Series")

adf.test(diff(diff(ts_ecom_train, lag = 4),lag=1))
adf.test(log_ts_ecom_train)
```

We can see that our difference of differences approach leads to stationarity, as proven by the Augmented Dickey Fuller test. As this series increases in magnitude, the associated seasonal variance also increases, and none of the differences taken above are able to attain visually consistent variance. We thus examine the effect of taking the logarithmic transform of this series prior to differencing.

We can see that the first order difference of the logarithm of the training series has near-constant variance, and also achieves stationarity by the ADF test. We do not require differencing of the log-transformed series to achieve stationarity.

## Modelling
We will start by using the AutoArima function to identify the SARIMA parameters that minimize AIC. We will explore modelling both the log transformed time series (handled by the argument "lambda=0") and the non-transformed series.

```{r}
log_model_auto <- auto.arima(ts_ecom_train, ic = 'aicc', lambda = 0)
model_auto <- auto.arima(ts_ecom_train, ic = 'aicc')

log_model_auto
model_auto
```

We can see that log transformed order is (0,1,0)(2,1,0)[4], while the non-transformed order is (0,1,1)(0,1,0)[4]. 

We will now fit models using these orders as well as a specification purely informed by our previous EDA for both the logarithm transformed series as well as the raw series.

The spike in the ACF at a lag of 1 quarter suggests a nonseasonal MA(1) (q=1) component and the spikes at intervals of 4 quarters of lag suggest a seasonal MA(1) (Q=1).  Additionally, the spike at at a lag of 1 quarter in the PACF and the spikes at intervals of 4 quarters of lag tells us that a a nonseasonal AR(1) (p=1) component and a seasonal AR(1) (P=1) component are appropriate for our initial model.  Therefore, our initial model will be of the form $ARIMA(1,1,1)(1,1,1)_4$

In the logarithm case, without accounting for seasonality, we observe a somewhat sinusoidal ACF with a PACF function showing no significant spikes beyond lag 4 that has steady variance with a difference of one.

```{r}
manual_model_raw <- Arima(ts_ecom_train, order=c(1,1,1), seasonal=c(1,1,1))
manual_model_log <- Arima(ts_ecom_train, order = c(0,1,4), seasonal=c(0,0,0), lambda=0)
```

We check each of these four models for validity: we use the Shapiro-Wilk and Box-Ljung tests. The former tests for normality of residuals within the training set, while the latter tests for autocorrelation within these same residuals.

```{r}
log_mod_auto_sw <- shapiro.test(log_model_auto $resid)
log_mod_auto_box <-Box.test(log_model_auto $resid, type = "Ljung-Box")

mod_auto_sw <-shapiro.test(model_auto $resid)
mod_auto_box <-Box.test(model_auto $resid, type = "Ljung-Box")

man_mod_raw_sw <-shapiro.test(manual_model_raw $resid)
man_mod_raw_box <-Box.test(manual_model_raw $resid, type = "Ljung-Box")

log_man_mod_sw <-shapiro.test(manual_model_log $resid)
log_man_mod_box <-Box.test(manual_model_log $resid, type = "Ljung-Box")

TestResults <- data.frame(cbind(rbind(log_mod_auto_sw$p.value,mod_auto_sw$p.value, 
                         man_mod_raw_sw$p.value, log_man_mod_sw$p.value),
                         rbind(log_mod_auto_box$p.value, mod_auto_box$p.value, 
                               man_mod_raw_box$p.value, log_man_mod_box$p.value)))

colnames(TestResults) <- c('Shapiro-Wilk', 'Box-Ljung')
rownames(TestResults) <- c('Log, Auto','Raw, Auto','Log, Manual', 'Raw, Manual')

TestResults
```

We compare these models on the basis of root mean square error (RMSE) of predictions in the validation holdout. Visuals of predictions versus actuals help us understand the forecasts.

```{r, warning=FALSE, message=FALSE}
calculate_rmse <- function(fcast, test){
  rmse <- sqrt(mean((fcast - test)^2))
}

par(mfrow=c(2,2), mai = c(.3, 0.3, 0.3, 0.1))

forecast_log_auto <- forecast(log_model_auto, h = 8, lambda=0)
forecast_auto <- forecast(model_auto, h = 8)
forecast_log_man <- forecast(manual_model_raw, h = 8)
forecast_man <- forecast(manual_model_log, h = 8, lambda=0)

RMSE_df <- data.frame(rbind(calculate_rmse(forecast_log_auto$mean,ts_ecom_test),
           calculate_rmse(forecast_auto$mean,ts_ecom_test), calculate_rmse(
             forecast_log_man$mean, ts_ecom_test), calculate_rmse(forecast_man$mean,
                                                                  ts_ecom_test)))

colnames(RMSE_df) <- c('RMSE')
rownames(RMSE_df) <- c('Log, Auto','Raw, Auto','Log, Manual', 'Raw, Manual')
RMSE_df

plot(forecast_log_auto, main="AutoArima Spec - Log Transformed")
lines(ts_ecom_test, col='green')
legend(2000,9,legend=c('Predicted','Observed'),col=c('blue','red'),lty=1, cex=0.8)
plot(forecast_auto, main="AutoArima Spec - Untransformed")
lines(ts_ecom_test, col='green')
plot(forecast_log_man, main="Manually Specified - Log Transformed")
lines(ts_ecom_test, col='green')
plot(forecast_man, main="Manually Specified - Untransformed")
lines(ts_ecom_test, col='green')

```

The AutoArima specification over the log transformed series has the best RMSE in out of sample comparisons. However, this specification also leads to non-normal residuals and potential autocorrelation in the residuals (as identified by the Shapiro-Wilk and Box-Ljung test in the previous section respectively). Thus, we will go forward with the AutoArima specification over the raw series, which has a comparable RMSE and non-significant results in both of these tests. Visually, these predictions are comparable. We finally use this model, trained over all available data, to predict values for 2017.

```{r, fig.height=3.45}
model_auto_all <- auto.arima(ts_ecom, ic = 'aicc')
plot(forecast(model_auto_all,h = 4), main='Forecasted 2017 E-Commerce Sales as Perc. of Total')
```

# Question 2:
<Intro> We will build a vector autoregressive model to forecast 4 time series.

## Exploration and Visualization

First, we load the time series, display a few values and <???>

```{r}
mts = read.csv(file = "data_2018Spring_MTS.txt", sep=' ')
ts_mts = ts(mts[ , c("series1", "series2", "series3", "series4")], start = c(1947, 1), freq = 12)
ts_mts_train = ts(ts_mts[time(ts_mts) < 1993, ], start = c(1947, 1), freq = 12)
ts_mts_test = ts(ts_mts[time(ts_mts) >= 1993, ], start = c(1993, 1), end = c(1993,12), freq = 12)
head(ts_mts_train)

#check for missing values
sum(is.na(ts_mts_train))

#summarize the series
summary(ts_mts_train)
```

Next, we create a plot of all time series in one single graph.

```{r, fig.width = 10, fig.height = 4}
ts.plot(ts_mts_train, gpars=list(main="Plot of all four series", ylab="Unknown units", col=c('blue','red','green','black')))

legend("topleft",c("Series 1","Series 2","Series 3","Series 4"), lty=1, col = c('blue','red','green','black'), bty='n', cex=.75)
```

In the following plot we look at the distribution of the four time series, as well as pairwise scatterplots and correlation coefficients.

```{r}
df_mts_train = data.frame(as.matrix(ts_mts_train), date=time(ts_mts_train))

ggpairs(df_mts_train[c('series1', 'series2', 'series3', 'series4')], title='Pairwise Scatterplot of series1, series2, series3 and series4')
```


```{r}
adf.test(df_mts_train$series1)$p.value; adf.test(df_mts_train$series2)$p.value
adf.test(df_mts_train$series3)$p.value; adf.test(df_mts_train$series4)$p.value
```

```{r warning=FALSE}
adf.test(diff(df_mts_train$series1))$p.value; adf.test(diff(df_mts_train$series2))$p.value
adf.test(diff(df_mts_train$series3))$p.value; adf.test(diff(df_mts_train$series4))$p.value
```

We skip looking at autocorrelation and partial autocorrelation function for the original time series and go straight to looking at the differenced acf and pacf.

```{r,fig.height=6}
acf(diff(ts_mts_train))
pacf(diff(ts_mts_train))
```


Next, we examine cointegration.

```{r}
po.test(df_mts_train[c('series1','series2')])$p.value; po.test(df_mts_train[c('series1','series3')])$p.value
po.test(df_mts_train[c('series1','series4')])$p.value; po.test(df_mts_train[c('series2','series3')])$p.value
po.test(df_mts_train[c('series2','series4')])$p.value; po.test(df_mts_train[c('series3','series4')])$p.value
```



## Modelling

First, we are searching for the order of the VAR model by using the VARselect function. 

```{r}
VARselect(diff(ts_mts_train), type = 'const')$selection
```

BIC selects VAR of order 2! For VAR models we usually use the BIC as criterion!!

```{r}
var = VAR(diff(ts_mts_train), p = 2, type = 'const')
```

Let us now test if the residuals are well behaved. We are conducting a Portmanteau Test.

```{r}
serial.test(var, type = 'PT.asymptotic')
```

We reject the null hypothesis of no serial correlation for the VAR(2) model. We also conducted this test for VAR(3), VAR(4) and VAR(5). For VAR(3) we received a p-value of around 0.015 and for VAR(4) we received a p-value of 0.08. The p-value for VAR(4) does not indicate statistical significance, but it is somewhat a borderline case, which is why we decided to chose a VAR(5) model - which happens to be the one that was selected by the AIC. The p-value for the VAR(5) models is about 0.23 and thus far away from statistical significance.

```{r}
var_model = VAR(diff(ts_mts_train), p = 5, type = 'const')
```


This model was informed by EDA and...
-----
Next, we want to strictly use an algorithmic approach to see if we can find a better model.

```{r, fig.width=10, fig.height=6}
diff_forecast = forecast(var_model, h=24)

endvals = tail(ts_mts_train,n=1)

integrate_diff_1 = cumsum(c(endvals[1], diff_forecast$forecast$series1$mean))
integrate_diff_2 = cumsum(c(endvals[2], diff_forecast$forecast$series2$mean))
integrate_diff_3 = cumsum(c(endvals[3], diff_forecast$forecast$series3$mean))
integrate_diff_4 = cumsum(c(endvals[4], diff_forecast$forecast$series4$mean))

diff_forecast_ts_diff = ts(cbind(integrate_diff_1, integrate_diff_2, integrate_diff_3, integrate_diff_4), start=c(1993, 1), freq=12)

ts_mts_train_window = window(ts_mts_train, start = c(1990,1))

par(mfrow=c(2,2))
ts.plot(ts_mts_train_window[,1], ts_mts_test[,1], diff_forecast_ts_diff[,1], col=c('black', 'green', 'blue'))
ts.plot(ts_mts_train_window[,2], ts_mts_test[,2], diff_forecast_ts_diff[,2], col=c('black', 'green', 'blue'))
ts.plot(ts_mts_train_window[,3], ts_mts_test[,3], diff_forecast_ts_diff[,3], col=c('black', 'green', 'blue'))
ts.plot(ts_mts_train_window[,4], ts_mts_test[,4], diff_forecast_ts_diff[,4], col=c('black', 'green', 'blue'))

```










